{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "daa558ff-d6da-4009-89ef-eb5d33d6ad12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchdata==0.7.1 in e:\\python\\python312\\lib\\site-packages (0.7.1)\n",
      "Requirement already satisfied: urllib3>=1.25 in e:\\python\\python312\\lib\\site-packages (from torchdata==0.7.1) (2.3.0)\n",
      "Requirement already satisfied: requests in e:\\python\\python312\\lib\\site-packages (from torchdata==0.7.1) (2.32.3)\n",
      "Requirement already satisfied: torch>=2 in e:\\python\\python312\\lib\\site-packages (from torchdata==0.7.1) (2.2.2)\n",
      "Requirement already satisfied: filelock in e:\\python\\python312\\lib\\site-packages (from torch>=2->torchdata==0.7.1) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in e:\\python\\python312\\lib\\site-packages (from torch>=2->torchdata==0.7.1) (4.12.2)\n",
      "Requirement already satisfied: sympy in e:\\python\\python312\\lib\\site-packages (from torch>=2->torchdata==0.7.1) (1.13.3)\n",
      "Requirement already satisfied: networkx in e:\\python\\python312\\lib\\site-packages (from torch>=2->torchdata==0.7.1) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in e:\\python\\python312\\lib\\site-packages (from torch>=2->torchdata==0.7.1) (3.1.5)\n",
      "Requirement already satisfied: fsspec in e:\\python\\python312\\lib\\site-packages (from torch>=2->torchdata==0.7.1) (2024.12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\python\\python312\\lib\\site-packages (from requests->torchdata==0.7.1) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\python\\python312\\lib\\site-packages (from requests->torchdata==0.7.1) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\python\\python312\\lib\\site-packages (from requests->torchdata==0.7.1) (2024.12.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\python\\python312\\lib\\site-packages (from jinja2->torch>=2->torchdata==0.7.1) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\python\\python312\\lib\\site-packages (from sympy->torch>=2->torchdata==0.7.1) (1.3.0)\n",
      "Requirement already satisfied: portalocker in e:\\python\\python312\\lib\\site-packages (3.1.1)\n",
      "Requirement already satisfied: pywin32>=226 in e:\\python\\python312\\lib\\site-packages (from portalocker) (308)\n",
      "Requirement already satisfied: pandas in e:\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in e:\\python\\python312\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\python\\python312\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\python\\python312\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in e:\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Collecting fr-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "     ---------------------------------------- 0.0/16.3 MB ? eta -:--:--\n",
      "     ----------------------- --------------- 10.0/16.3 MB 56.4 MB/s eta 0:00:01\n",
      "     ------------------------- ------------- 10.7/16.3 MB 26.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 14.7/16.3 MB 24.3 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 14.7/16.3 MB 24.3 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 14.7/16.3 MB 24.3 MB/s eta 0:00:01\n",
      "     --------------------------------------- 16.3/16.3 MB 13.5 MB/s eta 0:00:00\n",
      "Installing collected packages: fr-core-news-sm\n",
      "Successfully installed fr-core-news-sm-3.8.0\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!\"E:\\python\\python312\\python.exe\" -m pip install torchdata==0.7.1\n",
    "!\"E:\\python\\python312\\python.exe\" -m pip install portalocker\n",
    "!\"E:\\python\\python312\\python.exe\" -m pip install pandas\n",
    "!\"E:\\python\\python312\\python.exe\" -m spacy download fr_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2946417a-13aa-46f2-82c4-825b5742a9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17.2+cpu\n"
     ]
    }
   ],
   "source": [
    "import torchtext\n",
    "import torch\n",
    "print(torchtext.__version__)\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.datasets import multi30k, Multi30k\n",
    "from typing import Iterable, List\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8494fc0b-efb0-404e-a829-541ce34d6073",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"An asteroid set to swing by Earth in 2032 has a one in sixty three chance of smashing into our planet.\",\n",
    "             \"Porches, verandas, porticoes, and other types of outdoor coverings connected to a building have existed in various forms across the globe for centuries.\",\n",
    "             \"The Commander of the International Space Station interacted with students during an outreach activity.\",\n",
    "             \"You are awesome!\",\n",
    "             \"Hence, nil tax slab means tax is applicable, but the rebate brings the final tax liability to zero.\",\n",
    "             \"People who are emotionally immature often won’t take responsibility for their own actions when something goes wrong.\",    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69abb00a-5669-4f17-bc6f-1dd4f6582b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, sentences):\n",
    "        self.sentences = sentences\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        return self.sentences[ix]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb3bbfcb-09a0-4a03-ad49-cd8db5814448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Commander of the International Space Station interacted with students during an outreach activity.', 'Porches, verandas, porticoes, and other types of outdoor coverings connected to a building have existed in various forms across the globe for centuries.']\n",
      "['An asteroid set to swing by Earth in 2032 has a one in sixty three chance of smashing into our planet.', 'You are awesome!']\n",
      "['People who are emotionally immature often won’t take responsibility for their own actions when something goes wrong.', 'Hence, nil tax slab means tax is applicable, but the rebate brings the final tax liability to zero.']\n"
     ]
    }
   ],
   "source": [
    "custom_dataset = CustomDataset(sentences)\n",
    "\n",
    "batch_size=2\n",
    "\n",
    "dataloader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for itr in dataloader:\n",
    "    print(itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e0b3b8-3a34-4135-8f55-a584393e85bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57982b17-aa82-4036-a9f1-ff7fa17747cf",
   "metadata": {},
   "source": [
    "Creating tensors:\n",
    "- Tokenize sentences\n",
    "- Convert them into tensors of token indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d748359-68f1-4bf8-bf13-917b87220f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTokenizedDataset(Dataset):\n",
    "    def __init__(self, sentences, tokenizer, vocab):\n",
    "        self.sentences = sentences\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        tokens = self.tokenizer(self.sentences[ix])\n",
    "        tensor_indices = [self.vocab[token] for token in tokens]\n",
    "        return torch.tensor(tensor_indices)\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "vocab = build_vocab_from_iterator(map(tokenizer, sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71669306-c60c-4061-975a-31399cfb0c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_tokenized_dataset = CustomTokenizedDataset(sentences, tokenizer, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "938106d3-d033-445a-a13e-d89893c71c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length: 6\n",
      "ix[3]: tensor([81,  9, 19, 11])\n"
     ]
    }
   ],
   "source": [
    "print(f\"length: {len(custom_tokenized_dataset)}\")\n",
    "print(f\"ix[3]: {custom_tokenized_dataset[3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51676159-ed31-4d70-8883-b3f993f93c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_tokenized = DataLoader(custom_tokenized_dataset, batch_size=batch_size, shuffle=True, collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a688f8e8-5da8-4683-a88a-11762ee705f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [4] at entry 0 and [18] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata_loader_tokenized\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\python\\python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mE:\\python\\python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mE:\\python\\python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\python\\python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:277\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    217\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\python\\python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:121\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mE:\\python\\python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:174\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    172\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    173\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [4] at entry 0 and [18] at entry 1"
     ]
    }
   ],
   "source": [
    "# This will give error since tensors are not of same size\n",
    "for batch in data_loader_tokenized:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e2336902-e44e-44d0-a002-b0043a19bde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return pad_sequence(batch, batch_first=True, padding_value=0)\n",
    "\n",
    "def collate_fn_bfFALSE(batch):\n",
    "    return pad_sequence(batch, padding_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cf453a9c-331a-41f7-9635-4f440ca96a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_tokenized_padded = DataLoader(custom_tokenized_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3a30d506-60cd-4ec5-a2eb-48404001158e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2, 26,  4,  2, 42, 66, 67, 41, 78, 68, 29,  8, 53, 15,  1,  0,  0,  0,\n",
      "          0,  0,  0,  0],\n",
      "        [ 8, 18, 61,  6, 69, 23, 30,  3, 12, 37,  7, 49,  3, 62, 72, 25,  4, 64,\n",
      "         43, 51, 56,  1]])\n",
      "tensor([[39,  0, 47,  5, 63, 46,  5, 44, 17,  0, 22,  2, 59, 20,  2, 33,  5, 45,\n",
      "          6, 82,  1],\n",
      "        [81,  9, 19, 11,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0]])\n",
      "tensor([[57,  0, 75,  0, 58,  0, 16, 50, 73,  4, 52, 28, 27,  6,  7, 21, 38, 32,\n",
      "          3, 74, 34, 13,  2, 35, 10, 24,  1],\n",
      "        [55, 77,  9, 31, 40, 48, 79, 70, 60, 10, 71, 54, 14, 76, 65, 36, 80,  1,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0]])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader_tokenized_padded:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f3145335-c9b8-436a-8f87-cf6995e29e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hence', ',', 'nil', 'tax', 'slab', 'means', 'tax', 'is', 'applicable', ',', 'but', 'the', 'rebate', 'brings', 'the', 'final', 'tax', 'liability', 'to', 'zero', '.', ',', ',', ',', ',', ',', ',']\n",
      "##\n",
      "['porches', ',', 'verandas', ',', 'porticoes', ',', 'and', 'other', 'types', 'of', 'outdoor', 'coverings', 'connected', 'to', 'a', 'building', 'have', 'existed', 'in', 'various', 'forms', 'across', 'the', 'globe', 'for', 'centuries', '.']\n",
      "##\n",
      "['you', 'are', 'awesome', '!', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',']\n",
      "##\n",
      "['an', 'asteroid', 'set', 'to', 'swing', 'by', 'earth', 'in', '2032', 'has', 'a', 'one', 'in', 'sixty', 'three', 'chance', 'of', 'smashing', 'into', 'our', 'planet', '.']\n",
      "##\n",
      "['people', 'who', 'are', 'emotionally', 'immature', 'often', 'won’t', 'take', 'responsibility', 'for', 'their', 'own', 'actions', 'when', 'something', 'goes', 'wrong', '.']\n",
      "##\n",
      "['the', 'commander', 'of', 'the', 'international', 'space', 'station', 'interacted', 'with', 'students', 'during', 'an', 'outreach', 'activity', '.', ',', ',', ',']\n",
      "##\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader_tokenized_padded:\n",
    "    for row in batch:\n",
    "        print([vocab.get_itos()[ix] for ix in row])\n",
    "        print(\"##\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e8e36d82-c041-4cf7-b4a9-e21a118ca610",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_tokenized_padded_bfFalse = DataLoader(\n",
    "    custom_tokenized_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn_bfFALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b9a1ac99-588a-4983-ab37-795769da307f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[55, 81],\n",
      "        [77,  9],\n",
      "        [ 9, 19],\n",
      "        [31, 11],\n",
      "        [40,  0],\n",
      "        [48,  0],\n",
      "        [79,  0],\n",
      "        [70,  0],\n",
      "        [60,  0],\n",
      "        [10,  0],\n",
      "        [71,  0],\n",
      "        [54,  0],\n",
      "        [14,  0],\n",
      "        [76,  0],\n",
      "        [65,  0],\n",
      "        [36,  0],\n",
      "        [80,  0],\n",
      "        [ 1,  0]])\n",
      "tensor([[ 2, 39],\n",
      "        [26,  0],\n",
      "        [ 4, 47],\n",
      "        [ 2,  5],\n",
      "        [42, 63],\n",
      "        [66, 46],\n",
      "        [67,  5],\n",
      "        [41, 44],\n",
      "        [78, 17],\n",
      "        [68,  0],\n",
      "        [29, 22],\n",
      "        [ 8,  2],\n",
      "        [53, 59],\n",
      "        [15, 20],\n",
      "        [ 1,  2],\n",
      "        [ 0, 33],\n",
      "        [ 0,  5],\n",
      "        [ 0, 45],\n",
      "        [ 0,  6],\n",
      "        [ 0, 82],\n",
      "        [ 0,  1]])\n",
      "tensor([[57,  8],\n",
      "        [ 0, 18],\n",
      "        [75, 61],\n",
      "        [ 0,  6],\n",
      "        [58, 69],\n",
      "        [ 0, 23],\n",
      "        [16, 30],\n",
      "        [50,  3],\n",
      "        [73, 12],\n",
      "        [ 4, 37],\n",
      "        [52,  7],\n",
      "        [28, 49],\n",
      "        [27,  3],\n",
      "        [ 6, 62],\n",
      "        [ 7, 72],\n",
      "        [21, 25],\n",
      "        [38,  4],\n",
      "        [32, 64],\n",
      "        [ 3, 43],\n",
      "        [74, 51],\n",
      "        [34, 56],\n",
      "        [13,  1],\n",
      "        [ 2,  0],\n",
      "        [35,  0],\n",
      "        [10,  0],\n",
      "        [24,  0],\n",
      "        [ 1,  0]])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader_tokenized_padded_bfFalse:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cd12af15-9a6d-4f87-bde3-757f7b5c3181",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['porches', 'hence']\n",
      "##\n",
      "[',', ',']\n",
      "##\n",
      "['verandas', 'nil']\n",
      "##\n",
      "[',', 'tax']\n",
      "##\n",
      "['porticoes', 'slab']\n",
      "##\n",
      "[',', 'means']\n",
      "##\n",
      "['and', 'tax']\n",
      "##\n",
      "['other', 'is']\n",
      "##\n",
      "['types', 'applicable']\n",
      "##\n",
      "['of', ',']\n",
      "##\n",
      "['outdoor', 'but']\n",
      "##\n",
      "['coverings', 'the']\n",
      "##\n",
      "['connected', 'rebate']\n",
      "##\n",
      "['to', 'brings']\n",
      "##\n",
      "['a', 'the']\n",
      "##\n",
      "['building', 'final']\n",
      "##\n",
      "['have', 'tax']\n",
      "##\n",
      "['existed', 'liability']\n",
      "##\n",
      "['in', 'to']\n",
      "##\n",
      "['various', 'zero']\n",
      "##\n",
      "['forms', '.']\n",
      "##\n",
      "['across', ',']\n",
      "##\n",
      "['the', ',']\n",
      "##\n",
      "['globe', ',']\n",
      "##\n",
      "['for', ',']\n",
      "##\n",
      "['centuries', ',']\n",
      "##\n",
      "['.', ',']\n",
      "##\n",
      "['people', 'an']\n",
      "##\n",
      "['who', 'asteroid']\n",
      "##\n",
      "['are', 'set']\n",
      "##\n",
      "['emotionally', 'to']\n",
      "##\n",
      "['immature', 'swing']\n",
      "##\n",
      "['often', 'by']\n",
      "##\n",
      "['won’t', 'earth']\n",
      "##\n",
      "['take', 'in']\n",
      "##\n",
      "['responsibility', '2032']\n",
      "##\n",
      "['for', 'has']\n",
      "##\n",
      "['their', 'a']\n",
      "##\n",
      "['own', 'one']\n",
      "##\n",
      "['actions', 'in']\n",
      "##\n",
      "['when', 'sixty']\n",
      "##\n",
      "['something', 'three']\n",
      "##\n",
      "['goes', 'chance']\n",
      "##\n",
      "['wrong', 'of']\n",
      "##\n",
      "['.', 'smashing']\n",
      "##\n",
      "[',', 'into']\n",
      "##\n",
      "[',', 'our']\n",
      "##\n",
      "[',', 'planet']\n",
      "##\n",
      "[',', '.']\n",
      "##\n",
      "['the', 'you']\n",
      "##\n",
      "['commander', 'are']\n",
      "##\n",
      "['of', 'awesome']\n",
      "##\n",
      "['the', '!']\n",
      "##\n",
      "['international', ',']\n",
      "##\n",
      "['space', ',']\n",
      "##\n",
      "['station', ',']\n",
      "##\n",
      "['interacted', ',']\n",
      "##\n",
      "['with', ',']\n",
      "##\n",
      "['students', ',']\n",
      "##\n",
      "['during', ',']\n",
      "##\n",
      "['an', ',']\n",
      "##\n",
      "['outreach', ',']\n",
      "##\n",
      "['activity', ',']\n",
      "##\n",
      "['.', ',']\n",
      "##\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader_tokenized_padded_bfFalse:\n",
    "    for row in batch:\n",
    "        print([vocab.get_itos()[ix] for ix in row])\n",
    "        print(\"##\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "35812563-9a58-4731-add5-5deda602b260",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"Ceci est une phrase.\",\n",
    "    \"C'est un autre exemple de phrase.\",\n",
    "    \"Voici une troisième phrase.\",\n",
    "    \"Il fait beau aujourd'hui.\",\n",
    "    \"J'aime beaucoup la cuisine française.\",\n",
    "    \"Quel est ton plat préféré ?\",\n",
    "    \"Je t'adore.\",\n",
    "    \"Bon appétit !\",\n",
    "    \"Je suis en train d'apprendre le français.\",\n",
    "    \"Nous devons partir tôt demain matin.\",\n",
    "    \"Je suis heureux.\",\n",
    "    \"Le film était vraiment captivant !\",\n",
    "    \"Je suis là.\",\n",
    "    \"Je ne sais pas.\",\n",
    "    \"Je suis fatigué après une longue journée de travail.\",\n",
    "    \"Est-ce que tu as des projets pour le week-end ?\",\n",
    "    \"Je vais chez le médecin cet après-midi.\",\n",
    "    \"La musique adoucit les mœurs.\",\n",
    "    \"Je dois acheter du pain et du lait.\",\n",
    "    \"Il y a beaucoup de monde dans cette ville.\",\n",
    "    \"Merci beaucoup !\",\n",
    "    \"Au revoir !\",\n",
    "    \"Je suis ravi de vous rencontrer enfin !\",\n",
    "    \"Les vacances sont toujours trop courtes.\",\n",
    "    \"Je suis en retard.\",\n",
    "    \"Félicitations pour ton nouveau travail !\",\n",
    "    \"Je suis désolé, je ne peux pas venir à la réunion.\",\n",
    "    \"À quelle heure est le prochain train ?\",\n",
    "    \"Bonjour !\",\n",
    "    \"C'est génial !\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "022280fd-96f6-4764-a0ca-343cdd791e6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bonjour !',\n",
       " \"Je t'adore.\",\n",
       " 'Je suis là.',\n",
       " 'Au revoir !',\n",
       " 'Bon appétit !',\n",
       " \"C'est génial !\",\n",
       " 'Je ne sais pas.',\n",
       " 'Je suis heureux.',\n",
       " 'Merci beaucoup !',\n",
       " 'Je suis en retard.',\n",
       " 'Ceci est une phrase.',\n",
       " \"Il fait beau aujourd'hui.\",\n",
       " 'Voici une troisième phrase.',\n",
       " 'Quel est ton plat préféré ?',\n",
       " 'La musique adoucit les mœurs.',\n",
       " \"C'est un autre exemple de phrase.\",\n",
       " 'Le film était vraiment captivant !',\n",
       " 'Je dois acheter du pain et du lait.',\n",
       " 'Nous devons partir tôt demain matin.',\n",
       " \"J'aime beaucoup la cuisine française.\",\n",
       " 'À quelle heure est le prochain train ?',\n",
       " 'Je vais chez le médecin cet après-midi.',\n",
       " 'Je suis ravi de vous rencontrer enfin !',\n",
       " 'Les vacances sont toujours trop courtes.',\n",
       " 'Félicitations pour ton nouveau travail !',\n",
       " \"Je suis en train d'apprendre le français.\",\n",
       " 'Il y a beaucoup de monde dans cette ville.',\n",
       " 'Est-ce que tu as des projets pour le week-end ?',\n",
       " 'Je suis désolé, je ne peux pas venir à la réunion.',\n",
       " 'Je suis fatigué après une longue journée de travail.']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_sorted = sorted(corpus, key=lambda x: len(x))\n",
    "corpus_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ee6954fa-0a16-47d6-ac83-9c6c48ceea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrenchDataset(Dataset):\n",
    "    def __init__(self, sentences, tokenizer, vocab):\n",
    "        self.sentences = sentences\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        tokens = self.tokenizer(self.sentences[ix])\n",
    "        token_indices = [self.vocab[token] for token in tokens]\n",
    "        return torch.tensor(token_indices)\n",
    "\n",
    "french_tokenizer = get_tokenizer(\"spacy\", language='fr_core_news_sm')\n",
    "french_vocab = build_vocab_from_iterator(map(french_tokenizer, corpus))\n",
    "\n",
    "def collate_french(batch):\n",
    "    return pad_sequence(batch, batch_first=True, padding_value=0)\n",
    "    \n",
    "def collate_fn_fr(batch):\n",
    "    # Pad sequences within the batch to have equal lengths\n",
    "    tensor_batch=[]\n",
    "    for sample in batch:\n",
    "        tokens = french_tokenizer(sample)\n",
    "        tensor_batch.append(torch.tensor([french_vocab[token] for token in tokens]))\n",
    "         \n",
    "    padded_batch = pad_sequence(tensor_batch,batch_first=True)\n",
    "    return padded_batch\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "53bca6ae-1736-4632-9004-67c9583c0585",
   "metadata": {},
   "outputs": [],
   "source": [
    "french_batch_size = 4\n",
    "dataloader_french_basic = DataLoader(\n",
    "    corpus_sorted,\n",
    "    batch_size=french_batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6499aa1a-172a-40fe-95d3-969aceb06c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 27,   2,   0,   0],\n",
      "        [  1, 105,  41,   0],\n",
      "        [  1,   3,  82,   0],\n",
      "        [ 25, 101,   2,   0]])\n",
      "tensor([[ 26,  45,   2,   0,   0],\n",
      "        [ 11,   4,  74,   2,   0],\n",
      "        [  1,  16, 103,  17,   0],\n",
      "        [  1,   3,  76,   0,   0]])\n",
      "tensor([[ 35,   8,   2,   0,   0],\n",
      "        [  1,   3,  14, 100,   0],\n",
      "        [ 28,   4,  10,   9,   0],\n",
      "        [ 12,  69,  51,  49,   0]])\n",
      "tensor([[ 38,  10, 107,   9,   0,   0,   0,   0],\n",
      "        [ 37,   4,  19,  92,  95,   7,   0,   0],\n",
      "        [ 32,  85,  42,  80,  87,   0,   0,   0],\n",
      "        [ 11,   4, 111,  50,  68,   5,   9,   0]])\n",
      "tensor([[ 33,  71, 122, 117,  52,   2,   0,   0,   0],\n",
      "        [  1,  63,  40,  13,  89,  67,  13,  79,   0],\n",
      "        [ 36,  62,  90, 110,  60,  83,   0,   0,   0],\n",
      "        [ 31,  43,   8,  15,  57,  73,   0,   0,   0]])\n",
      "tensor([[120,  97,  75,   4,   6,  93,  20,   7],\n",
      "        [  1, 113,  55,   6,  86,  53,  47,   0],\n",
      "        [  1,   3,  98,   5, 116,  99,  66,   2],\n",
      "        [ 34, 112, 104, 106, 108,  56,   0,   0]])\n",
      "tensor([[ 30,  18,  19,  88,  21,   2,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,   3,  14,  20,  58,  44,   6,  72,   0,   0,   0,   0,   0],\n",
      "        [ 12, 119,  39,   8,   5,  84,  59,  54, 115,   0,   0,   0,   0],\n",
      "        [ 29,  24,  96, 109,  48,  61,  94,  18,   6, 118,  23,  65,   7]])\n",
      "tensor([[  1,   3,  64,  22,  77,  16,  91,  17, 114, 121,  15, 102,   0],\n",
      "        [  1,   3,  70,  46,  10,  81,  78,   5,  21,   0,   0,   0,   0]])\n"
     ]
    }
   ],
   "source": [
    "for itr in dataloader_french_basic:\n",
    "    print(itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "73057b68-98d8-423d-bec3-110c389dd4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "french_dataset = FrenchDataset(corpus_sorted, french_tokenizer, french_vocab)\n",
    "french_batch_size = 4\n",
    "dataloader_french = DataLoader(\n",
    "    french_dataset,\n",
    "    batch_size=french_batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_french)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4b61ef83-360e-45f2-929a-48c426041b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 27,   2,   0,   0],\n",
      "        [  1, 105,  41,   0],\n",
      "        [  1,   3,  82,   0],\n",
      "        [ 25, 101,   2,   0]])\n",
      "tensor([[ 26,  45,   2,   0,   0],\n",
      "        [ 11,   4,  74,   2,   0],\n",
      "        [  1,  16, 103,  17,   0],\n",
      "        [  1,   3,  76,   0,   0]])\n",
      "tensor([[ 35,   8,   2,   0,   0],\n",
      "        [  1,   3,  14, 100,   0],\n",
      "        [ 28,   4,  10,   9,   0],\n",
      "        [ 12,  69,  51,  49,   0]])\n",
      "tensor([[ 38,  10, 107,   9,   0,   0,   0,   0],\n",
      "        [ 37,   4,  19,  92,  95,   7,   0,   0],\n",
      "        [ 32,  85,  42,  80,  87,   0,   0,   0],\n",
      "        [ 11,   4, 111,  50,  68,   5,   9,   0]])\n",
      "tensor([[ 33,  71, 122, 117,  52,   2,   0,   0,   0],\n",
      "        [  1,  63,  40,  13,  89,  67,  13,  79,   0],\n",
      "        [ 36,  62,  90, 110,  60,  83,   0,   0,   0],\n",
      "        [ 31,  43,   8,  15,  57,  73,   0,   0,   0]])\n",
      "tensor([[120,  97,  75,   4,   6,  93,  20,   7],\n",
      "        [  1, 113,  55,   6,  86,  53,  47,   0],\n",
      "        [  1,   3,  98,   5, 116,  99,  66,   2],\n",
      "        [ 34, 112, 104, 106, 108,  56,   0,   0]])\n",
      "tensor([[ 30,  18,  19,  88,  21,   2,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,   3,  14,  20,  58,  44,   6,  72,   0,   0,   0,   0,   0],\n",
      "        [ 12, 119,  39,   8,   5,  84,  59,  54, 115,   0,   0,   0,   0],\n",
      "        [ 29,  24,  96, 109,  48,  61,  94,  18,   6, 118,  23,  65,   7]])\n",
      "tensor([[  1,   3,  64,  22,  77,  16,  91,  17, 114, 121,  15, 102,   0],\n",
      "        [  1,   3,  70,  46,  10,  81,  78,   5,  21,   0,   0,   0,   0]])\n"
     ]
    }
   ],
   "source": [
    "for itr in dataloader_french:\n",
    "    print(itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14205de8-71e6-4f6e-aef6-2cc336216f47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b65124-71d4-48b2-92b1-d9adb5c479bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
